{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quick reminder:* To run the code in a cell, either click on the \"play\" icon above, or press Shift+Enter. Cells can be run as many times as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split multi-sample file -- Many samples per row, 1 column per sample\n",
    "<i><font size=2 color=\"grey\">Version 1.0, last modified September 2017<br>\n",
    "Pandas 0.19.2<br>\n",
    "Python 3.6<br>\n",
    "</font></i>\n",
    "  \n",
    "  \n",
    "This notebook contains code to split a file containing data for multiple samples. <font color=\"red\"><strong>Expected Format:</strong></font> many sample per row, 1 column per sample.   \n",
    "\n",
    "**<u>Expected input:</u>**  \n",
    "  \n",
    "Input file to split, and mapping between user-defined ID and ImmPort Experiment Sample Accession. Input file must be a **text file**. The expectation is that the headers contain the <strong>user-defined ID <font color=\"red\">ONLY</font></strong>.\n",
    "  \n",
    "**<u>Output:</u>**  \n",
    "\n",
    "Directory containing one file per experiment sample accession.   \n",
    "  \n",
    "**<u>Parameters:</u>**  \n",
    "<font color=\"DarkRed\"><strong>Please</strong></font> change the following parameters by commenting out or editing accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Study accession:\n",
    "sdy_acc = \"SDYxxx\"\n",
    "\n",
    "## Experiment accession:\n",
    "exp_acc = \"EXPxxxxx\"\n",
    "\n",
    "## What type of data is contained in the file to split?\n",
    "file_type = \"gene_expression\"\n",
    "#file_type = \"microbiome_results\"\n",
    "#file_type = \"RNA_seq\"\n",
    "#file_type = \"microarray_results\"\n",
    "\n",
    "## Path to file to split:\n",
    "input_file = \"placeholder/path/to/input_file\"\n",
    "\n",
    "## Is the file to split tab or comma separated?\n",
    "input_file_format = \"tsv\"\n",
    "#input_file_format = \"csv\"\n",
    "\n",
    "## How many columns contain information about probe, type of probe, gene, gene names etc?\n",
    "## These columns will be included in each of the individual sample files.\n",
    "info_column = 1\n",
    "\n",
    "## What is the best desription of the value represented?\n",
    "measure = \"Value\"\n",
    "#measure = \"Count\"\n",
    "#measure = \"Signal\"\n",
    "\n",
    "## Path to mapping file\n",
    "mapping_file = \"placeholder/path/to/mapping_file\"\n",
    "\n",
    "## How are the fields separated in the mapping file?\n",
    "sep_mapping = \"\\t\"\n",
    "#sep_mapping = \",\"\n",
    "\n",
    "## Which column contains the user-defined ID in the mapping file? Count starts at 1.\n",
    "exp_sample_id_mapping = 1\n",
    "\n",
    "## Which column contains the experiment sample accession in the mapping file? Count starts at 1.\n",
    "exp_sample_acc_mapping = 2\n",
    "\n",
    "## Does the mapping file contain a header line?\n",
    "mapping_header = True\n",
    "#mapping_header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code go through the mapping file to build a dictionary containing the user-defined ID to experiment sample accessions, and create a file path for each accession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create empties\n",
    "esIDs = {}\n",
    "es_files = {}\n",
    "no_match = []\n",
    "\n",
    "## Set up parameters\n",
    "uid_idx = exp_sample_id_mapping - 1\n",
    "es_acc_idx = exp_sample_acc_mapping - 1\n",
    "extension =  file_type + \".txt\"\n",
    "read_fctns = {\"tsv\" : pd.read_table, \"csv\": pd.read_csv}\n",
    "\n",
    "## Create path to output directory:\n",
    "## directory will be ./SDYxxx/EXPxxxxx/ where . is the directory containing the input file\n",
    "output_path_file = os.path.split(os.path.realpath(input_file))[0]\n",
    "sdy_dir = os.path.join(output_path_file, sdy_acc)\n",
    "os.makedirs(sdy_dir, exist_ok=True)\n",
    "exp_dir = os.path.join(sdy_dir, exp_acc)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "## Go through mapping file:\n",
    "try:\n",
    "    with open(mapping_file, \"r\") as mf:\n",
    "        if mapping_header:\n",
    "            mf.readline()\n",
    "        for line in mf:\n",
    "            uid = line.strip().split(sep_mapping)[uid_idx]\n",
    "            es_acc = line.strip().split(sep_mapping)[es_acc_idx]\n",
    "            es_acc = es_acc.strip(\"\\\"\")\n",
    "            uid = uid.strip(\"\\\"\")\n",
    "            esIDs[uid] = es_acc\n",
    "\n",
    "            ## assuming one line per experiment sample, create file paths here.\n",
    "            es_file_name = \"_\".join([sdy_acc, exp_acc, es_acc, extension])\n",
    "            es_file_path = os.path.join(exp_dir, es_file_name)\n",
    "            es_files[uid] = es_file_path\n",
    "except:\n",
    "    print(\"Couldn't open the mapping file. Please check parameters indicated above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code populate the files that were just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Go through file to split:\n",
    "try:\n",
    "    df = read_fctns[input_file_format](input_file)\n",
    "    ## subset the first few informational columns that will appear in each file:\n",
    "    df_info = df.iloc[:, 0:info_column]\n",
    "    \n",
    "    ## For each accession in the mapping file, populate the files:\n",
    "    for ids in es_files:\n",
    "        if ids in df.columns:\n",
    "            df_subset = pd.concat([df_info, df[ids]], axis=1, join_axes=[df.index])\n",
    "            df_subset.rename(columns = {df_subset.columns[info_column]:measure}, inplace=True)\n",
    "            df_subset.to_csv(es_files[ids], sep=\"\\t\", index=False)\n",
    "        else:\n",
    "            no_match.append(ids)\n",
    "            \n",
    "    print(\"%s files were created in %s\\n\" % ((len(es_files) - len(no_match)), exp_dir))\n",
    "    print(\"Files are ready for upload.\")\n",
    "    if (no_match):\n",
    "        print(\"The following columns header were not matched to an accession in the mapping file:\")\n",
    "        print(\"(No files corresponding to these headers were generated)\")\n",
    "        print(\"\\n\".join(no_match))\n",
    "        \n",
    "\n",
    "except:\n",
    "    print(\"Couldn't read file to split. Please check path or file format in the parameters above.\")\n",
    "    print(\"Given path was %s\" % (input_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If files are uploaded after experiment samples accessions were generated, each individual file will need to be remapped to its corresponding experiment sample accession. The following code generates the file containing the mapping between Experiment Sample Accession and File Info ID for the 'Move Archive' Tool.  \n",
    "<font color=\"DarkRed\"><strong>Please</strong></font> change the parameters first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Path to upload database report -- this is the file in the confirmation email of successful upload\n",
    "upload_report = \"placeholder/path/to/upload_report/ImmPort.report.Database.xxxx.txt\"\n",
    "\n",
    "## What value to use for file detail?\n",
    "file_detail = \"Custom assay result\"\n",
    "#file_detail = \"Gene expression result\"\n",
    "#file_detail = \"RNA sequencing result\"\n",
    "#file_detail = \"Genotyping result\"\n",
    "#file_detail = \"TPM\"\n",
    "#file_detail = \"RPKM\"\n",
    "#file_detail = \"FPKM\"\n",
    "#file_detail = \"Custom\"\n",
    "#file_detail = \"FASTQ\"\n",
    "#file_detail = \"Illumina BeadArray\"\n",
    "#file_detail = \"Illumina GA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set up empty\n",
    "file_info = {}\n",
    "\n",
    "## Path for mapping file:\n",
    "## file will be in directory containing the SDYxxx directory\n",
    "fid_mapping_filename = \"_\".join([sdy_acc, exp_acc, \"ES_ACC_2_FID.txt\"])\n",
    "fid_mapping_path = os.path.join(output_path_file, fid_mapping_filename)\n",
    "\n",
    "try:\n",
    "    ## Go through data base report\n",
    "    with open(upload_report, \"r\") as ur:\n",
    "        for line in ur:\n",
    "            if line.startswith(\"Stored in:file_info\"):\n",
    "                path = line.split()[4]\n",
    "                filename = os.path.split(path)[1]\n",
    "                es = filename.split(\"_\")[2]\n",
    "                fid  = path.split(\".\")[-2]\n",
    "                file_info[es] = fid\n",
    "\n",
    "    try:\n",
    "        ## Generate mapping file experiment sample - file info ID\n",
    "        with open(fid_mapping_path, \"w\") as fm:\n",
    "            for exp_acc_nb in es_files:\n",
    "                fm.write(\"\\t\".join([file_info[esIDs[exp_acc_nb]], esIDs[exp_acc_nb], file_detail]) + \"\\n\")\n",
    "        print(\"The file to associate File Info IDs to Experiment Sample Accession was generated:\")\n",
    "        print(fid_mapping_path)\n",
    "        \n",
    "    except:\n",
    "        print(\"The file mapping File Info ID to Experiment Sample Accession could not be generated.\")\n",
    "        print(\"Please check that the database report is the right one.\")\n",
    "\n",
    "except:\n",
    "    print(\"The database report could not be read. Please check the path above.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
