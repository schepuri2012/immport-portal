{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quick reminder:* To run the code in a cell, either click on the \"play\" icon above, or press Shift+Enter. Cells can be run as many times as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split multi-sample file -- 1 sample per row\n",
    "<i><font size=2 color=\"grey\">Version 1.0, last modified September 2017<br>\n",
    "Pandas 0.19.2<br>\n",
    "Python 3.6<br>\n",
    "</font></i>\n",
    "  \n",
    "  \n",
    "This notebook contains code to split a file containing data for multiple samples. <font color=\"red\"><strong>Expected Format:</strong></font> 1 sample per row, many rows per sample.   \n",
    "\n",
    "**<u>Expected input:</u>**  \n",
    "  \n",
    "Input file to split, and mapping between user-defined ID and ImmPort Experiment Sample Accession. Input file must be a **text file**.\n",
    "  \n",
    "**<u>Output:</u>**  \n",
    "\n",
    "Directory containing one file per experiment sample accession.   \n",
    "  \n",
    "**<u>Parameters:</u>**  \n",
    "<font color=\"DarkRed\"><strong>Please</strong></font> change the following parameters by commenting out or editing accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Study accession:\n",
    "sdy_acc = \"SDYxxx\"\n",
    "\n",
    "## Experiment accession:\n",
    "exp_acc = \"EXPxxxxx\"\n",
    "\n",
    "## What type of data is contained in the file to split?\n",
    "file_type = \"gene_expression\"\n",
    "#file_type = \"microbiome_results\"\n",
    "#file_type = \"RNA_seq\"\n",
    "#file_type = \"microarray_results\"\n",
    "\n",
    "## Path to file to split:\n",
    "input_file = \"placeholder/path/to/input_file\"\n",
    "\n",
    "## Is the file to split tab or comma separated?\n",
    "input_file_format = \"tsv\"\n",
    "#input_file_format = \"csv\"\n",
    "\n",
    "## Which column contains the user-defined ID? Count starts at 1.\n",
    "exp_sample_id = 1\n",
    "\n",
    "## Does the file to split contain a header line?\n",
    "input_header = True\n",
    "#input_header = False\n",
    "\n",
    "## Path to mapping file\n",
    "mapping_file = \"placeholder/path/to/mapping_file\"\n",
    "\n",
    "## How are the fields separated in the mapping file?\n",
    "sep_mapping = \"\\t\"\n",
    "#sep_mapping = \",\"\n",
    "\n",
    "## Which column contains the user-defined ID in the mapping file? Count starts at 1.\n",
    "exp_sample_id_mapping = 1\n",
    "\n",
    "## Which column contains the experiment sample accession in the mapping file? Count starts at 1.\n",
    "exp_sample_acc_mapping = 2\n",
    "\n",
    "## Does the mapping file contain a header line?\n",
    "mapping_header = True\n",
    "#mapping_header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code go through the mapping file to build a dictionary containing the user-defined ID to experiment sample accessions, and create a file path for each accession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create empties\n",
    "esIDs = {}\n",
    "es_files = {}\n",
    "no_match = []\n",
    "\n",
    "## Set up parameters\n",
    "uid_idx = exp_sample_id_mapping - 1\n",
    "es_acc_idx = exp_sample_acc_mapping - 1\n",
    "input_id_idx = exp_sample_id - 1\n",
    "extension =  file_type + \".txt\"\n",
    "read_fctns = {\"tsv\" : pd.read_table, \"csv\": pd.read_csv}\n",
    "head_input = None\n",
    "if input_header:\n",
    "    head_input = 0\n",
    "\n",
    "## Create path to output directory:\n",
    "## directory will be ./SDYxxx/EXPxxxxx/ where . is the directory containing the input file\n",
    "output_path_file = os.path.split(os.path.realpath(input_file))[0]\n",
    "sdy_dir = os.path.join(output_path_file, sdy_acc)\n",
    "os.makedirs(sdy_dir, exist_ok=True)\n",
    "exp_dir = os.path.join(sdy_dir, exp_acc)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "## Go through mapping file:\n",
    "try:\n",
    "    with open(mapping_file, \"r\") as mf:\n",
    "        if mapping_header:\n",
    "            mf.readline()\n",
    "        for line in mf:\n",
    "            uid = line.strip().split(sep_mapping)[uid_idx]\n",
    "            es_acc = line.strip().split(sep_mapping)[es_acc_idx]\n",
    "            es_acc = es_acc.strip(\"\\\"\")\n",
    "            uid = uid.strip(\"\\\"\")\n",
    "            esIDs[uid] = es_acc\n",
    "\n",
    "            ## assuming one line per experiment sample, create file paths here.\n",
    "            es_file_name = \"_\".join([sdy_acc, exp_acc, es_acc, extension])\n",
    "            es_file_path = os.path.join(exp_dir, es_file_name)\n",
    "            es_files[uid] = es_file_path\n",
    "except:\n",
    "    print(\"Couldn't open the mapping file. Please check parameters indicated above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code generate and populate one file per experiment sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Go through file to split:\n",
    "try:\n",
    "    df = read_fctns[input_file_format](input_file, header=head_input)\n",
    "    ## Check that all user defined IDs have a match\n",
    "    acc_in_file = set(df.iloc[:,input_id_idx])\n",
    "    for acc in acc_in_file:\n",
    "        if acc not in es_files:\n",
    "            no_match.append(acc)\n",
    "        else:\n",
    "        ## For each accession in the mapping file, populate the files:\n",
    "            df_subset = df[df.iloc[:,input_id_idx] == acc].copy()\n",
    "            df_subset.drop(df.columns[[input_id_idx]], axis=1, inplace=True)\n",
    "            df_subset.to_csv(es_files[acc], sep=\"\\t\", header=input_header, index=False)\n",
    "            \n",
    "    print(\"%s files were created in %s\\n\" % ((len(es_files)-len(no_match)), exp_dir))\n",
    "    print(\"Files are ready for upload.\")\n",
    "    if (no_match):\n",
    "        print(\"The following user-defined IDs were not matched to an accession in the mapping file:\\n\")\n",
    "        print(\"\\n\".join(no_match))\n",
    "\n",
    "except:\n",
    "    print(\"Couldn't read file to split. Please check path or file format in the parameters above.\")\n",
    "    print(\"Given path was %s\" % (input_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If files are uploaded after experiment samples accessions were generated, each individual file will need to be remapped to its corresponding experiment sample accession. The following code generates the file containing the mapping between Experiment Sample Accession and File Info ID for the 'Move Archive' Tool.  \n",
    "<font color=\"DarkRed\"><strong>Please</strong></font> change the parameters first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Path to upload database report -- this is the file in the confirmation email of successful upload\n",
    "upload_report = \"placeholder/path/to/upload_report/ImmPort.report.Database.xxxx.txt\"\n",
    "\n",
    "## What value to use for file detail?\n",
    "file_detail = \"Custom assay result\"\n",
    "#file_detail = \"Gene expression result\"\n",
    "#file_detail = \"RNA sequencing result\"\n",
    "#file_detail = \"Genotyping result\"\n",
    "#file_detail = \"TPM\"\n",
    "#file_detail = \"RPKM\"\n",
    "#file_detail = \"FPKM\"\n",
    "#file_detail = \"Custom\"\n",
    "#file_detail = \"FASTQ\"\n",
    "#file_detail = \"Illumina BeadArray\"\n",
    "#file_detail = \"Illumina GA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set up empty\n",
    "file_info = {}\n",
    "\n",
    "## Path for mapping file:\n",
    "## file will be in directory containing the SDYxxx directory\n",
    "fid_mapping_filename = \"_\".join([sdy_acc, exp_acc, \"ES_ACC_2_FID.txt\"])\n",
    "fid_mapping_path = os.path.join(output_path_file, fid_mapping_filename)\n",
    "\n",
    "try:\n",
    "    ## Go through data base report\n",
    "    with open(upload_report, \"r\") as ur:\n",
    "        for line in ur:\n",
    "            if line.startswith(\"Stored in:file_info\"):\n",
    "                path = line.split()[4]\n",
    "                filename = os.path.split(path)[1]\n",
    "                es = filename.split(\"_\")[2]\n",
    "                fid  = path.split(\".\")[-2]\n",
    "                file_info[es] = fid\n",
    "\n",
    "    try:\n",
    "        ## Generate mapping file experiment sample - file info ID\n",
    "        with open(fid_mapping_path, \"w\") as fm:\n",
    "            for exp_acc_nb in es_files:\n",
    "                fm.write(\"\\t\".join([file_info[esIDs[exp_acc_nb]], esIDs[exp_acc_nb], file_detail]) + \"\\n\")\n",
    "        print(\"The file to associate File Info IDs to Experiment Sample Accession was generated:\")\n",
    "        print(fid_mapping_path)\n",
    "        \n",
    "    except:\n",
    "        print(\"The file mapping File Info ID to Experiment Sample Accession could not be generated.\")\n",
    "        print(\"Please check that the database report is the right one.\")\n",
    "\n",
    "except:\n",
    "    print(\"The database report could not be read. Please check the path above.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
